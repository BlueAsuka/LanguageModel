{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x193d5768870>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "torch.manual_seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3414,  0.3946,  0.1850,  0.4800,  0.4665,  0.4236,  0.1108,  0.4214],\n",
      "        [ 0.1050,  0.0785,  0.1202,  0.3850,  0.1208,  0.0399, -0.2124,  0.1151],\n",
      "        [-0.1811, -0.2858, -0.1526, -0.0554, -0.2847, -0.3668, -0.5001, -0.2568],\n",
      "        [ 0.1481,  0.1472,  0.1916,  0.2362,  0.1843,  0.0915,  0.0318,  0.2275],\n",
      "        [ 0.6363,  0.6430,  0.5677,  0.8342,  0.8813,  0.6279,  0.4974,  0.6862],\n",
      "        [ 0.1280,  0.0237,  0.1140,  0.3661,  0.0697, -0.0255, -0.1636,  0.0466],\n",
      "        [-0.2919, -0.3817, -0.2634,  0.1275, -0.2355, -0.3530, -0.6830, -0.3209],\n",
      "        [ 0.4372,  0.3150,  0.3136,  0.5926,  0.5401,  0.1971,  0.1597,  0.3939]],\n",
      "       grad_fn=<SelectBackward0>) \n",
      "\n",
      "tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1.]]) \n",
      "\n",
      "tensor([[ 0.3414,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
      "        [ 0.1050,  0.0785,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
      "        [-0.1811, -0.2858, -0.1526,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
      "        [ 0.1481,  0.1472,  0.1916,  0.2362,    -inf,    -inf,    -inf,    -inf],\n",
      "        [ 0.6363,  0.6430,  0.5677,  0.8342,  0.8813,    -inf,    -inf,    -inf],\n",
      "        [ 0.1280,  0.0237,  0.1140,  0.3661,  0.0697, -0.0255,    -inf,    -inf],\n",
      "        [-0.2919, -0.3817, -0.2634,  0.1275, -0.2355, -0.3530, -0.6830,    -inf],\n",
      "        [ 0.4372,  0.3150,  0.3136,  0.5926,  0.5401,  0.1971,  0.1597,  0.3939]],\n",
      "       grad_fn=<SelectBackward0>) \n",
      "\n",
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5066, 0.4934, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3413, 0.3074, 0.3512, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2418, 0.2416, 0.2526, 0.2641, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1839, 0.1852, 0.1717, 0.2242, 0.2350, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1679, 0.1512, 0.1655, 0.2130, 0.1584, 0.1440, 0.0000, 0.0000],\n",
      "        [0.1401, 0.1280, 0.1441, 0.2131, 0.1482, 0.1318, 0.0947, 0.0000],\n",
      "        [0.1325, 0.1173, 0.1171, 0.1548, 0.1469, 0.1042, 0.1004, 0.1269]],\n",
      "       grad_fn=<SelectBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# An illustration of the attention mechanism\n",
    "B, T, C = 4, 8, 32\n",
    "x = torch.rand(B, T, C)\n",
    "\n",
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias=False)    \n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "k = key(x)      # (B, T, 16)\n",
    "q = query(x)    # (B, T, 16)\n",
    "\n",
    "w = q @ k.transpose(-2, -1) # (B, T, 16) (B, 16, T) => (B, T, T)\n",
    "print(w[0], '\\n')\n",
    "\n",
    "tril = torch.tril((torch.ones(T, T)))\n",
    "print(tril, '\\n')\n",
    "\n",
    "w = w.masked_fill(tril==0, float('-inf'))\n",
    "print(w[0], '\\n')\n",
    "\n",
    "w = F.softmax(w, dim=-1)\n",
    "print(w[0], '\\n')\n",
    "\n",
    "out = w @ x\n",
    "\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "\n",
    "v = value(x)\n",
    "\n",
    "out = w @ v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
